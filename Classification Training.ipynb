{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76057e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a695e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the paths to your image directories\n",
    "bleeding_dir = \"bleeding/Images\"\n",
    "non_bleeding_dir = \"non-bleeding/Images\"\n",
    "\n",
    "# Initialize empty lists to store image data\n",
    "image_data = []\n",
    "labels = []\n",
    "\n",
    "# Function to load images from a directory and append to the lists\n",
    "def load_images_from_directory(directory, label):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".png\"):  # Change the file extension as needed\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = Image.open(img_path)\n",
    "#             img = img.resize() \n",
    "            img_array = np.array(img)/255.0  \n",
    "            image_data.append(img_array)\n",
    "            labels.append(label)\n",
    "\n",
    "# Load images from the \"bleeding\" directory\n",
    "load_images_from_directory(bleeding_dir, label=\"bleeding\")\n",
    "\n",
    "# Load images from the \"non-bleeding\" directory\n",
    "load_images_from_directory(non_bleeding_dir, label=\"non-bleeding\")\n",
    "\n",
    "# Create a DataFrame from the image data and labels\n",
    "data = {'image': image_data, 'label': labels}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Now, df contains all your image data with corresponding labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad294e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[0.00392156862745098, 0.00392156862745098, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[0.00392156862745098, 0.00392156862745098, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>[[[0.00392156862745098, 0.00392156862745098, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>[[[0.00392156862745098, 0.00392156862745098, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>[[[0.00392156862745098, 0.00392156862745098, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>[[[0.00392156862745098, 0.00392156862745098, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>[[[0.00392156862745098, 0.00392156862745098, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2618 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image  label\n",
       "0     [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0\n",
       "1     [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0\n",
       "2     [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0\n",
       "3     [[[0.00392156862745098, 0.00392156862745098, 0...      0\n",
       "4     [[[0.00392156862745098, 0.00392156862745098, 0...      0\n",
       "...                                                 ...    ...\n",
       "2613  [[[0.00392156862745098, 0.00392156862745098, 0...      1\n",
       "2614  [[[0.00392156862745098, 0.00392156862745098, 0...      1\n",
       "2615  [[[0.00392156862745098, 0.00392156862745098, 0...      1\n",
       "2616  [[[0.00392156862745098, 0.00392156862745098, 0...      1\n",
       "2617  [[[0.00392156862745098, 0.00392156862745098, 0...      1\n",
       "\n",
       "[2618 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd6e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d637b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = np.array(df['image'].tolist())\n",
    "y = np.array(df['label'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "034fc07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images to a smaller size, e.g., (64, 64, 3)\n",
    "X_train = np.array([tf.image.resize(image, (64, 64)) for image in X_train])\n",
    "X_test = np.array([tf.image.resize(image, (64, 64)) for image in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bf2174",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc31ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')  # 2 classes: bleeding and non-bleeding\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92737f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use 'categorical_crossentropy' if you one-hot encode labels\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4e7fa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "66/66 [==============================] - 13s 172ms/step - loss: 0.5295 - accuracy: 0.7330 - val_loss: 0.3967 - val_accuracy: 0.8206\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 11s 164ms/step - loss: 0.3353 - accuracy: 0.8639 - val_loss: 0.4504 - val_accuracy: 0.7863\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 9s 141ms/step - loss: 0.2483 - accuracy: 0.9064 - val_loss: 0.2519 - val_accuracy: 0.8912\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 10s 145ms/step - loss: 0.1653 - accuracy: 0.9413 - val_loss: 0.1591 - val_accuracy: 0.9466\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 10s 153ms/step - loss: 0.1345 - accuracy: 0.9565 - val_loss: 0.1476 - val_accuracy: 0.9447\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 12s 185ms/step - loss: 0.1001 - accuracy: 0.9690 - val_loss: 0.1038 - val_accuracy: 0.9676\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 14s 216ms/step - loss: 0.0635 - accuracy: 0.9828 - val_loss: 0.0710 - val_accuracy: 0.9828\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 14s 205ms/step - loss: 0.0540 - accuracy: 0.9871 - val_loss: 0.1197 - val_accuracy: 0.9561\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 14s 212ms/step - loss: 0.0461 - accuracy: 0.9871 - val_loss: 0.1395 - val_accuracy: 0.9485\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 13s 196ms/step - loss: 0.0450 - accuracy: 0.9838 - val_loss: 0.0696 - val_accuracy: 0.9752\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "500b328d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 - 1s - loss: 0.0696 - accuracy: 0.9752 - 536ms/epoch - 32ms/step\n",
      "Test accuracy: 0.9751908183097839\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11c8c58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TIRTH JOSHI\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# You can save the trained model for later use\n",
    "model.save(\"image_classification_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13389ad2",
   "metadata": {},
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d1ead51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Define the ResNet50 model with transfer learning\n",
    "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90b63f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9756d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the custom classifier on top of the base model\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(2, activation='softmax')(x)  # 2 classes: bleeding and non-bleeding\n",
    "\n",
    "model = models.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52ccdad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97c1fe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "66/66 [==============================] - 37s 470ms/step - loss: 0.7940 - accuracy: 0.4919 - val_loss: 0.6910 - val_accuracy: 0.5019\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 31s 478ms/step - loss: 0.7010 - accuracy: 0.5310 - val_loss: 0.6734 - val_accuracy: 0.7233\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 40s 607ms/step - loss: 0.6776 - accuracy: 0.5778 - val_loss: 0.6526 - val_accuracy: 0.7176\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 38s 583ms/step - loss: 0.6622 - accuracy: 0.5888 - val_loss: 0.6250 - val_accuracy: 0.7042\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 37s 564ms/step - loss: 0.6482 - accuracy: 0.6285 - val_loss: 0.6198 - val_accuracy: 0.6775\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 36s 553ms/step - loss: 0.6339 - accuracy: 0.6480 - val_loss: 0.5973 - val_accuracy: 0.7156\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 36s 554ms/step - loss: 0.6202 - accuracy: 0.6628 - val_loss: 0.5841 - val_accuracy: 0.7634\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 40s 610ms/step - loss: 0.6148 - accuracy: 0.6734 - val_loss: 0.5783 - val_accuracy: 0.7729\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 36s 549ms/step - loss: 0.6038 - accuracy: 0.6834 - val_loss: 0.5648 - val_accuracy: 0.7233\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 35s 535ms/step - loss: 0.5925 - accuracy: 0.6977 - val_loss: 0.5513 - val_accuracy: 0.7748\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a5df62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 - 7s - loss: 0.5513 - accuracy: 0.7748 - 7s/epoch - 429ms/step\n",
      "Test accuracy: 0.7748091816902161\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4ab9a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model for later use\n",
    "model.save(\"resnet_image_classification_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bb74f5",
   "metadata": {},
   "source": [
    "# CNN Residual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bffb356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use float32 data type\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f7ad5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model with residual connections\n",
    "inputs = layers.Input(shape=(64, 64, 3))\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "# Add a residual connection here\n",
    "residual = layers.MaxPooling2D((2, 2))(x)  # Apply max-pooling to the residual\n",
    "x = layers.MaxPooling2D((2, 2))(x)  # Apply max-pooling to the current path as well\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "# Add the residual connection back\n",
    "x = layers.Add()([x, residual])\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(2, activation='softmax')(x)  # 2 classes: bleeding and non-bleeding\n",
    "\n",
    "model = models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1f86e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 62, 62, 32)           896       ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPoolin  (None, 31, 31, 32)           0         ['conv2d_12[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 31, 31, 64)           18496     ['max_pooling2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooli  (None, 15, 15, 64)           0         ['conv2d_13[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 15, 15, 64)           36928     ['max_pooling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 15, 15, 64)           0         ['conv2d_13[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 15, 15, 64)           0         ['conv2d_14[0][0]',           \n",
      "                                                                     'max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)         (None, 14400)                0         ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 64)                   921664    ['flatten_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 2)                    130       ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 978114 (3.73 MB)\n",
      "Trainable params: 978114 (3.73 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f41f63b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use 'categorical_crossentropy' if you one-hot encode labels\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76ba2b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "66/66 [==============================] - 12s 167ms/step - loss: 0.4217 - accuracy: 0.8061 - val_loss: 0.2715 - val_accuracy: 0.8760\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 10s 155ms/step - loss: 0.2150 - accuracy: 0.9169 - val_loss: 0.2131 - val_accuracy: 0.9198\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 10s 158ms/step - loss: 0.1404 - accuracy: 0.9479 - val_loss: 0.1295 - val_accuracy: 0.9580\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 11s 166ms/step - loss: 0.0842 - accuracy: 0.9752 - val_loss: 0.1213 - val_accuracy: 0.9561\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 11s 174ms/step - loss: 0.0546 - accuracy: 0.9838 - val_loss: 0.0953 - val_accuracy: 0.9676\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 12s 178ms/step - loss: 0.0449 - accuracy: 0.9871 - val_loss: 0.1121 - val_accuracy: 0.9676\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 12s 181ms/step - loss: 0.0407 - accuracy: 0.9866 - val_loss: 0.0749 - val_accuracy: 0.9809\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 12s 183ms/step - loss: 0.0653 - accuracy: 0.9761 - val_loss: 0.1233 - val_accuracy: 0.9542\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 12s 183ms/step - loss: 0.0441 - accuracy: 0.9885 - val_loss: 0.0964 - val_accuracy: 0.9752\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 12s 188ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 0.0532 - val_accuracy: 0.9885\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d2a3bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 - 1s - loss: 0.0532 - accuracy: 0.9885 - 662ms/epoch - 39ms/step\n",
      "Test accuracy: 0.9885495901107788\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0658434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model for later use\n",
    "model.save(\"image_classification_model_with_residuals.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e6a98e",
   "metadata": {},
   "source": [
    "# Deep CNN with Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46fea273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a deeper CNN model with multiple residual connections\n",
    "inputs = layers.Input(shape=(64, 64, 3))\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# First residual connection\n",
    "residual1 = layers.Conv2D(64, (1, 1), strides=(2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "# Adjust the strides to match dimensions\n",
    "x = layers.Conv2D(64, (1, 1), strides=(2, 2), padding='same')(x)\n",
    "x = layers.Add()([x, residual1])\n",
    "\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# Second residual connection\n",
    "residual2 = layers.Conv2D(128, (1, 1), strides=(2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "# Adjust the strides to match dimensions\n",
    "x = layers.Conv2D(128, (1, 1), strides=(2, 2), padding='same')(x)\n",
    "x = layers.Add()([x, residual2])\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "outputs = layers.Dense(2, activation='softmax')(x)  # 2 classes: bleeding and non-bleeding\n",
    "\n",
    "model = models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6bad6481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)       [(None, 64, 64, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)          (None, 62, 62, 32)           896       ['input_10[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_22 (MaxPooli  (None, 31, 31, 32)           0         ['conv2d_60[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)          (None, 31, 31, 64)           18496     ['max_pooling2d_22[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)          (None, 31, 31, 64)           36928     ['conv2d_62[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)          (None, 16, 16, 64)           4160      ['conv2d_63[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)          (None, 16, 16, 64)           2112      ['max_pooling2d_22[0][0]']    \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, 16, 16, 64)           0         ['conv2d_64[0][0]',           \n",
      "                                                                     'conv2d_61[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_23 (MaxPooli  (None, 8, 8, 64)             0         ['add_13[0][0]']              \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)          (None, 8, 8, 128)            73856     ['max_pooling2d_23[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_66[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)          (None, 4, 4, 128)            16512     ['conv2d_67[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)          (None, 4, 4, 128)            8320      ['max_pooling2d_23[0][0]']    \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, 4, 4, 128)            0         ['conv2d_68[0][0]',           \n",
      "                                                                     'conv2d_65[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_10 (Flatten)        (None, 2048)                 0         ['add_14[0][0]']              \n",
      "                                                                                                  \n",
      " dense_21 (Dense)            (None, 128)                  262272    ['flatten_10[0][0]']          \n",
      "                                                                                                  \n",
      " dense_22 (Dense)            (None, 128)                  16512     ['dense_21[0][0]']            \n",
      "                                                                                                  \n",
      " dense_23 (Dense)            (None, 2)                    258       ['dense_22[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 587906 (2.24 MB)\n",
      "Trainable params: 587906 (2.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "33d74891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use 'categorical_crossentropy' if you one-hot encode labels\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab7489a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "66/66 [==============================] - 25s 309ms/step - loss: 0.4599 - accuracy: 0.7875 - val_loss: 0.3421 - val_accuracy: 0.8626\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 22s 328ms/step - loss: 0.2865 - accuracy: 0.8777 - val_loss: 0.7338 - val_accuracy: 0.8454\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 20s 301ms/step - loss: 0.1789 - accuracy: 0.9355 - val_loss: 0.1560 - val_accuracy: 0.9294\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 20s 299ms/step - loss: 0.1011 - accuracy: 0.9680 - val_loss: 0.0692 - val_accuracy: 0.9828\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 21s 314ms/step - loss: 0.0608 - accuracy: 0.9785 - val_loss: 0.0523 - val_accuracy: 0.9790\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 23s 354ms/step - loss: 0.0343 - accuracy: 0.9900 - val_loss: 0.0431 - val_accuracy: 0.9866\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 23s 353ms/step - loss: 0.0455 - accuracy: 0.9885 - val_loss: 0.0552 - val_accuracy: 0.9828\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 23s 348ms/step - loss: 0.0344 - accuracy: 0.9900 - val_loss: 0.1294 - val_accuracy: 0.9542\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 23s 352ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.0305 - val_accuracy: 0.9924\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 23s 351ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0168 - val_accuracy: 0.9981\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "444f2d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 - 1s - loss: 0.0168 - accuracy: 0.9981 - 1s/epoch - 88ms/step\n",
      "Test accuracy: 0.9980915784835815\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bba3c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model for later use\n",
    "model.save(\"deep_image_classification_model_with_residuals.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
